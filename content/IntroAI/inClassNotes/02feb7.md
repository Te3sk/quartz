[[IntroAI/assets/slides/5-2022-oltre_ricerca_classica.pdf|slide]]
-------------- manca la prima parte -------------

# algoritmo hill climbing - steepest ascent
si fa meno di DF, non si tengono neanche i fratelli (a parte casi eccezionali)
## il problema delle 8 regine (formulazione a stato completo)
vogliamo minimizzare le coppie di regine che si attaccano, nella figura ci sono già i valori dei successori (di h se si spostassero). tra tutti i possibili successori migliori (minori, in questo caso 12) se ne sceglie uno a caso.
non è detto che si vada sempre verso lo zero, se si finisce in un minimo locale non si può migliorare
con questo algoritmo, il problema si blocca l'86% delle volte
in media però in 4 passi trova la soluzione o in 3 passi si accorge di essersi bloccato
## miglioramenti
1. invece di fermarsi per minore o uguale, ci si ferma solo per minore, se è uguale si continua
2. scappa dalle situazione di max locale in modo più agevole, qua la stocasticità ci piace
3. con prima scelta: migliora l'efficienza
4. se ci si ferma in un max locale, riparte in un altro punto scelto a caso
	- nelle 8 regine con 7 ripartenze si ha successo
	- la riuscita dipende dalla forma del panorama degli stati, molti minimi locali abbassano p e trovare il buon punto di ripartenza è difficile
# tempra simulata
combina il climbing con la scelta stocastica. 
analogia con la tempra dei metalli (ricottura simultata): se c'è un difetto reticolato
all'inizio ammettiamo molte mosse stocastiche e poi sempre meno
## per ascesa
se migliora lo staso corrente viene espanso
- se peggiora/rimane pari invece che fermarci si continua con una certa probabilità p=(slide) di successo. La probabilità p è inversamente proporzionale al peggioramento -> se la mossa peggiora molto la p si abbassa molto
- fattore temperatura: t decresce al progeredire dell'algo. secondo un piano definito. quando t divenda bassa ($e^{-\infty}\approx 0$) si ferma la prob. di prendere mosse peggiorative 
si può tornare indietro ma con una prob. guidata. Si può riformulare lo stesso algo cercando un min invece che un max
### analisi
questo algo ingloba la stocasticità in modo *smart*.
### parametri
si sceglie t in modo tale che i valori medi di delta e e p sia circa 0.5
# ricerca local beam
fin'ora ci portavamo dietro un solo nodo per risparmiare memoria, qui ne teniamo fino a k e ad ogni passo genera i successori di tutti i k, se si trova un goal ci si ferma altrimenti si continua con i k migliori tra questi.
non si fa k restart (riparte da 0) ma si riparte da dove siamo arrivati.
se k diventa molto grande diventa inefficiente come bf, se k=1 è come beam search
# beam search stocastica
è come se k generasse una nuova generazione, nella versione stocastica, come k successori non si scelgono i migliori ma quelli con probabilità maggiore di portare ai migliori
da qui in poi
- organismo/popolazione di individui = stato
- progenie = successori
- fitness (valore di f) = idoneità
introduciamo questa terminologia perché vogliamo parlare di processi che simulano la selezione naturale
## algoritmi genetici/evolutivi
due genitori vanno a "procreare" i nuovi successori, per farlo si accoppiano
c'è una popolazione iniziale con k stati/individi, ognuno dei quali è rappresentato da una stringa (es. nelle 8 regine o 8 cifre che rappresentano le colonne o 24 bit (3 bit per colonna)). gli individui sono valutati da una funzione fitness (es. nelle 8 regine -> numero di coppie che non si attaccano).  si selezionano gli indi. per gli accoppiamenti con una prob proporzionale alla fitness, le coppie danno vita alla generazione successiva.
la pop. ottenuta dovrebbe essere migliore (non è sempre detto, ma di base i genitori migliori generano figli migliori)
si ripete fino ad ottenere stati abbastanza buoni o finché non si smette di migliorare
### nascita di un figlio
se i genitori sono molto simili, l'evuluzione tende a rallentare
inizialmente gli spostamenti sono maggiori, poi tendono a rallentare

integriamo aspetti del k-beam e stocasticità
## algoritmi genetici
tutto questo da luogo all'area del *natural computing* che prende ispirazione dai meccanismi naturali
combinano la tendenza a salire della beam search stocastica e l'interscambio di info tra thread paralleli di ricerca
dobbiamo riuscire a scrivere le rappresentazioni del problema in sottostringhe (non è sempre facile)
	es. le formiche vanno a giro a caso, quando una raggiunge l'obiettivo chiama le altre, che andando rilasciano feromoni. chi ha fatto il percorso più breve ha lasciato la scia di feromoni più intensa, le altre poi seguono il percorso più denso. così le formiche si scambiano indirettamente il thread di informazioni rilasciando i feromoni.

---
# spazi continui
fin'ora ci siamo mossi su spazi discreti, ma molti problemi reali hanno spazi di ricerca continui.
lo stato è descritto da variabili continui x1,...,xn; in questo caso il fattore di ramificazione è **infinito**, ma in realtà molti strumenti matematici portano ad approcci anche molto efficienti
## gradient
se f è continua e differenziabile, il min e il max si può cercare con il gradiente, che da la direzione di max pendenza nel punto (dove andare/di quanto). non serve cercare fra gli infiniti successori
hill climbing iterativo -> prox stato = prex stato +/-(se vogliamo salire o scender) uno step size (costante tipicamente minore di 1).
# oltre la ricerca classica
## soluzioni più complesse
succede questa cosa, ma se succede questa faccio quest'altra
## azioni non deterministiche
tipicamente avevamo un'azione e una relativa conseguenza
	es. aspirapolvere
	se aspira una stanza sporca la pulisce, ma a volte pulisce anche una stanza adiacente, se aspira in una stanza pulita, a volte rilascia sporco
	bisogna variare il modello con il *piano di contingenza* che sarà un piano condizionale e volendo con cicli